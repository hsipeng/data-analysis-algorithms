{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 贝叶斯分类算法时一大类分类算法的总称。贝叶斯分类算法以样本可能属于某类的概率来作为分类依据。朴素贝叶斯分类算法时贝叶斯分类算法中最简单的一种。\n",
    "\n",
    "# 注：朴素的意思时条件概率独立性\n",
    "\n",
    "# 朴素贝叶斯的思想是这样的：如果一个事物在一些属性条件发生的情况下，事物属于A的概率>属于B的概率，则判定事物属于A。\n",
    "\n",
    "# 通俗来说比如，在某条大街上，有100人，其中有50个美国人，50个非洲人，看到一个讲英语的黑人，那么我们是怎么去判断他来自哪里？\n",
    "# 算法步骤\n",
    "\n",
    "# 1. 分解各类先验样本数据中的特征；\n",
    "\n",
    "# 2. 计算各类数据中，各特征的条件概率；(比如：特征1出现的情况下，属于A类的概率p(A|特征1)，属于B类的概率p(B|特征1)，属于C类的概率p(C|特征1)......)\n",
    "\n",
    "# 3. 分解待分类数据中的特征(特征1、特征2、特征3、特征4......)\n",
    "\n",
    "# 4. 计算各特征的各条件概率的乘积，如下所示：\n",
    "\n",
    "#     判断为A类的概率：p(A|特征1) * p(A|特征2) * p(A|特征3) * p(A|特征4)......\n",
    "\n",
    "#     判断为B类的概率：p(B|特征1) * p(B|特征2) * p(B|特征3) * p(B|特征4)......\n",
    "\n",
    "#    判断为C类的概率：p(C|特征1) * p(C|特征2) * p(C|特征3) * p(C|特征4)......\n",
    "\n",
    "#    ......\n",
    "\n",
    "# 5. 结果中的最大值就是该样本所属的类别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用大量邮件先验数据，使用朴素贝叶斯分类算法来自动识别垃圾邮件\n",
    "\n",
    "#过滤垃圾邮件\n",
    "def textParse(bigString):      #正则表达式进行文本解析\n",
    "      import re\n",
    "      listOfTokens = re.split(r'\\W*', bigString)\n",
    "      return [tok.lower() for tok in listOfTokens if len(tok) > 2]\n",
    "\n",
    "def spamTest()\n",
    "      docList = []; classList = []; fullText = []\n",
    "      for i in range(1,26):     #导入并解析文本文件\n",
    "             wordList = textParse(open('email/spam/%d.txt'%i).read())\n",
    "             docList.append(wordList)\n",
    "             fullText.extend(wordList)\n",
    "             classList.append(1)\n",
    "             wordList = textParse(open('email/ham/%d.txt'%i).read())\n",
    "             docList.append(wordList)\n",
    "             fullText.extend(wordList)\n",
    "             classList.append(0)\n",
    "      vocabList = createVocabList(docList)\n",
    "      trainingSet = range(50);testSet = []\n",
    "      for i in range(10):                  #随机构建训练集\n",
    "             randIndex = int(random.uniform(0, len(trainingSet)))\n",
    "             testSet.append(trainingSet[randIndex]) #随机挑选一个文档索引号放入测试集\n",
    "              del(trainingSet[randIndex])  #将该文档索引号从训练集中剔除\n",
    "       trainMat = []; trainClasses = []\n",
    "       for docIndex in trainingSet:\n",
    "              trainMat.append(setOfWords2Vec(vocabList, docList[docIndex]))\n",
    "              trainClasses.append(classList[docIndex])\n",
    "       p0V,p1V,pSpam = trainNBO(array(trainMat), array(trainClasses))\n",
    "       errorCount = 0\n",
    "       for docIndex in testSet:        #对测试集进行分类\n",
    "             wordVector = setOfWords2Vec(vocabList, docList[docIndex])\n",
    "             if classifyNB(array(wordVector), p0V,p1V != classList[docIndex]:\n",
    "                 errorCount +=1\n",
    "        print 'the error rate is:', float(errorCount)/len(testSet)"
   ]
  }
 ]
}