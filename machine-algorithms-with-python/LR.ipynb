{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.8"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lineage逻辑回归是一种简单而又效果不错的分类算法。\n",
    "\n",
    "# 什么是回归：比如说我们有两类数据，各有50个点组成，当我们把这些点画出来，会有一条线区分这两组数据，我们拟合出这个曲线（因为很有可能是非线性的），就是回归。我们通过大量的数据找出这条线，并拟合出这条线的表达式，再有新数据，我们就以这条线为区分来实现分类。\n",
    "\n",
    "# 1) 算法目标()？\n",
    "\n",
    "# 大白话：计算各点的y值到拟合线的垂直距离，如果距离>0，分为类A；距离<0，分为类B。\n",
    "\n",
    "# 2) 如何得到拟合线呢？\n",
    "\n",
    "# 大白话：只能先假设，因为线或面的函数都可以表达成y(拟合)=w1 * x1 + w2 * x2 + w3 * x3 + ... ，其中的w是待定参数，而x是数据的各维度特征值，因而上述问题就变成了样本y(x) - y(拟合) > 0? A：B\n",
    "\n",
    "# 3) 如何求解出一套最优的w参数呢?\n",
    "\n",
    "# 基本思路：代入”先验数据“来逆推求解，但针对不等式求解参数极其困难，通用的解决方法，将对不等式的求解做一个转换：a.将”样本y(x) - y(拟合)“的差值压缩到一个0~1的小区间；b.然后代入大量的样本特征值，从而得到一系列的输出结果；c.再将这些输出结果跟样本的先验类别比较，并根据比较情况来调整拟合线的参数值，从而是拟合线的参数逼近最优。从而将问题转化为逼近求解的典型数学问题。\n",
    "\n",
    "\n",
    "# 使用sigmoid函数，就是让样板点经过运算后得到的结果限制在0~1之间，压缩数据的巨幅震荡，从而方便得到样本点的分类标签(分类以sigmoid函数的计算结果是否大于0.5为依据)\n",
    "\n",
    "\n",
    "# 算法思想的数学表述\n",
    "# 把数据集的特征值设为x1，x2，x3......，求出它们的回归系数wj，设z=w1 * x1 + w2 * x2......，然后将z值代入sigmoid函数并判断结果，即可得到分类标签\n",
    "\n",
    "# 问题在于如何得到一组合适的参数wj？\n",
    "\n",
    "# 通过解析的途径很难求解，而通过迭代的方法可以比较便捷地找到最优解。简单来说，就是不断用样本特征值代入算式，计算出结果后跟其实际标签进行比较，根据差值来修正参数，然后再代入新的样本值计算，循环往复，直到无需修正或已到达预设的迭代次数。\n",
    "\n",
    "# 注：此过程用梯度上升来实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "def loadDataSet():\n",
    "      dataMat = []\n",
    "      labelMat = []\n",
    "      fr = open('/Users/lirawx/Documents/Workspace/data-analysis-algorithms/machine-algorithms-with-python/testSet_lr.txt')\n",
    "      for line in fr.readlines():\n",
    "            lineArr = line.strip().split(',')\n",
    "            dataMat.append([1.0, float(lineArr[0]), float(lineArr[1])])\n",
    "            labelMat.append(int(lineArr[2]))\n",
    "      return dataMat, labelMat\n",
    "\n",
    "def sigmoid(inX):\n",
    "      return 1.0/(1+exp(-inX))\n",
    "\n",
    "def gradAscent(dataMatln, classLabels):\n",
    "      dataMatrix = mat(dataMatln)  # 将先验数据集转换为NumPy矩阵\n",
    "      labelMat = mat(classLabels).transpose() #将先验数据的类标签转换为NumPy矩阵\n",
    "   \n",
    "      m,n = shape(dataMatrix)\n",
    "      alpha = 0.001     #设置逼近步长调整系数\n",
    "      maxCycles = 500  #设置最大迭代次数为500\n",
    "      weights = ones((n,1)) #weights即为需要迭代求解的参数向量\n",
    "\n",
    "      for k in range(maxCycles): #heavy on matrix operations\n",
    "            h = sigmoid(dataMatrix * weights) #代入样本向量求得“样本y” sigmoid转换值\n",
    "            error = (labelMat - h)    #求差\n",
    "            weights = weights + alpha * dataMatrix.transpose() * error #根据差值调整参数向量\n",
    "      return weights\n",
    "\n",
    "# 我们的数据集有两个特征值分别是x1,x2。在代码中又增设了x0变量。\n",
    "\n",
    "# 结果，返回了特征值的回归系数：\n",
    "\n",
    "# [[4.12414349]\n",
    "\n",
    "#  [0.48007329]\n",
    "\n",
    "#  [-0.6168482]]\n",
    "\n",
    "# 我们得出x1和x2的关系(设x0 = 1)，0=4.12414349+0.48007329*x1 - 0.6168482*x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[[ 1.97114556]\n [ 0.29193191]\n [-0.28910564]]\n"
    }
   ],
   "source": [
    "dataSet, labels = loadDataSet()\n",
    "weights = gradAscent(dataSet, labels)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}